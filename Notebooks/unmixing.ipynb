{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Imports](#Imports)\n",
    "\n",
    "2. [Parameter List](#Parameter-List)\n",
    "    1. [Documentation](#Documentation)\n",
    "    2. [Parameters](#Parameters)\n",
    "\n",
    "3. [Function Definitions](#Function-Definitions)\n",
    "    1. [Global Variables](#Global-Variables)\n",
    "    2. [Functions for Loading Datasets](#Functions-for-Loading-Datasets)\n",
    "    3. [Functions for Reading / Writing Precomputed Results](#Functions-for-Reading-/-Writing-Precomputed-Results)\n",
    "    4. [Helper Classes for Running PySptool Algorithms](#Helper-Classes-for-Running-PySptool-Algorithms)\n",
    "    5. [Helper Classes for Running scikit-learn Algorithms](#Helper-Classes-for-Running-scikit-learn-Algorithms)\n",
    "    6. [Helper Classes for Running Joint Algorithms](#Helper-Classes-for-Running-Joint-Algorithms)\n",
    "    7. [Help Functions for Executing Algorithms](#Help-Functions-for-Executing-Algorithms)\n",
    "    8. [Function for Displaying a HSI Cube](#Function-for-Displaying-a-HSI-Cube)\n",
    "    9. [Function for Displaying Endmembers and Abundance Maps](#Function-for-Displaying-Endmembers-and-Abundance-Maps)\n",
    "    10. [Function for Displaying a Matrix](#Function-for-Displaying-a-Matrix)\n",
    "    11. [Helper Functions for Matching Items](#Helper-Functions-for-Matching-Items)\n",
    "    12. [Function for Comparing Endmembers](#Function-for-Comparing-Endmembers)\n",
    "    13. [Function for Comparing Abundance Maps](#Function-for-Comparing-Abundance-Maps)\n",
    "\n",
    "4. [Class Definitions](#Class-Definitions)\n",
    "    1. [Joint NMF Class](#Joint-NMF-Class)\n",
    "    2. [GR NMF Class](#GR-NMF-Class)\n",
    "\n",
    "5. [Data Loading](#Data-Loading)\n",
    "    1. [Read Hyperspectral Image](#Read-Hyperspectral-Image)\n",
    "    2. [Read Ground Truth](#Read-Ground-Truth)\n",
    "\n",
    "6. [Label Summary](#Label-Summary)\n",
    "\n",
    "7. [Image Summary](#Image-Summary)\n",
    "    1. [Display the Spectrum for a Given Pixel](#Display-the-Spectrum-for-a-Given-Pixel)\n",
    "    2. [Display Several Spectral Bands for All Pixels](#Display-Several-Spectral-Bands-for-All-Pixels)\n",
    "\n",
    "8. [Ground Truth Summary](#Ground-Truth-Summary)\n",
    "\n",
    "9. [Algorithms](#Algorithms)\n",
    "    1. [Endmember Extraction Algorithms](#Endmember-Extraction-Algorithms)\n",
    "        1. [Automatic Target Generation Process (ATGP)](#Automatic-Target-Generation-Process-&#40;ATGP&#41;)\n",
    "        2. [Fast Iterative Pixel Purity Index (FIPPI)](#Fast-Iterative-Pixel-Purity-Index-&#40;FIPPI&#41;)\n",
    "        3. [N-FINDR](#N-FINDR)\n",
    "        4. [Pixel Purity Index (PPI)](#Pixel-Purity-Index-&#40;PPI&#41;)\n",
    "    2. [Abundance Map Extraction Algorithms](#Abundance-Map-Extraction-Algorithms)\n",
    "        1. [Isomap](#Isomap)\n",
    "        2. [Locally Linear Embedding (LLE)](#Locally-Linear-Embedding-&#40;LLE&#41;)\n",
    "        3. [Modified Locally Linear Embedding (MLLE)](#Modified-Locally-Linear-Embedding-&#40;MLLE&#41;)\n",
    "        4. [Hessian-Based Locally Linear Embedding (HLLE)](#Hessian-Based-Locally-Linear-Embedding-&#40;HLLE&#41;)\n",
    "        5. [Spectral Embedding (SE)](#Spectral-Embedding-&#40;SE&#41;)\n",
    "        6. [Local Tangent Space Alignment (LTSA)](#Local-Tangent-Space-Alignment-&#40;LTSA&#41;)\n",
    "        7. [Metric Multi-Dimensional Scaling (MMDS)](#Metric-Multi-Dimensional-Scaling-&#40;MMDS&#41;)\n",
    "        8. [Nonmetric Multi-Dimensional Scaling (NMDS)](#Nonmetric-Multi-Dimensional-Scaling-&#40;NMDS&#41;)\n",
    "        9. [t-distributed Stochastic Neighbor Embedding (TSNE)](#t-distributed-Stochastic-Neighbor-Embedding-&#40;TSNE&#41;)\n",
    "    3. [Joint Unmixing Algorithms](#Joint-Unmixing-Algorithms)\n",
    "        1. [Linear Algorithms](#Linear-Algorithms)\n",
    "            1. [Principal Component Analysis (PCA)](#Principal-Component-Analysis-&#40;PCA&#41;)\n",
    "            2. [Nonnegative Matrix Factorization (NMF)](#Nonnegative-Matrix-Factorization-&#40;NMF&#41;)\n",
    "            3. [Joint Nonnegative Matrix Factorization (Joint-NMF)](#Joint-Nonnegative-Matrix-Factorization-&#40;Joint-NMF&#41;)\n",
    "            4. [Graph Regularized Nonnegative Matrix Factorization (GR-NMF)](#Graph-Regularized-Nonnegative-Matrix-Factorization-&#40;GR-NMF&#41;)\n",
    "\n",
    "10. [Results](#Results)\n",
    "    1. [Endmember Comparison](#Endmember-Comparison)\n",
    "        1. [Ground Truth Endmember Comparison](#Ground-Truth-Endmember-Comparison)\n",
    "            1. [Ground Truth Endmember vs. Endmember Algorithms](#Ground-Truth-Endmember-vs.-Endmember-Algorithms)\n",
    "            2. [Ground Truth Endmember vs. Abundance Maps Algorithms](#Ground-Truth-Endmember-vs.-Abundance-Maps-Algorithms)\n",
    "            3. [Ground Truth Endmember vs. Joint Algorithms](#Ground-Truth-Endmember-vs.-Joint-Algorithms)\n",
    "        2. [Internal Algorithm Endmember Comparison](#Internal-Algorithm-Endmember-Comparison)\n",
    "            1. [Endmember Comparison for Endmember Algorithms](#Endmember-Comparison-for-Endmember-Algorithms)\n",
    "            2. [Endmember Comparison for Abundance Maps Algorithms](#Endmember-Comparison-for-Abundance-Maps-Algorithms)\n",
    "            3. [Endmember Comparison for Joint Algorithms](#Endmember-Comparison-for-Joint-Algorithms)\n",
    "        3. [External Algorithm Endmember Comparison](#External-Algorithm-Endmember-Comparison)\n",
    "            1. [Endmember Comparison for Endmember Algorithms vs. Abundance Maps Algorithms](#Endmember-Comparison-for-Endmember-Algorithms-vs.-Abundance-Maps-Algorithms)\n",
    "            2. [Endmember Comparison for Endmember Algorithms vs. Joint Algorithms](#Endmember-Comparison-for-Endmember-Algorithms-vs.-Joint-Algorithms)\n",
    "            3. [Endmember Comparison for Abundance Maps Algorithms vs. Joint Algorithms](#Endmember-Comparison-for-Abundance-Maps-Algorithms-vs.-Joint-Algorithms)\n",
    "    2. [Abundance Maps Comparison](#Abundance-Maps-Comparison)\n",
    "        1. [Ground Truth Abundance Maps Comparison](#Ground-Truth-Abundance-Maps-Comparison)\n",
    "            1. [Ground Truth Abundance Maps vs. Endmember Algorithms](#Ground-Truth-Abundance-Maps-vs.-Endmember-Algorithms)\n",
    "            2. [Ground Truth Abundance Maps vs. Abundance Maps Algorithms](#Ground-Truth-Abundance-Maps-vs.-Abundance-Maps-Algorithms)\n",
    "            3. [Ground Truth Abundance Maps vs. Joint Algorithms](#Ground-Truth-Abundance-Maps-vs.-Joint-Algorithms)\n",
    "        2. [Internal Algorithm Abundance Maps Comparison](#Internal-Algorithm-Abundance-Maps-Comparison)\n",
    "            1. [Abundance Maps Comparison for Endmember Algorithms](#Abundance-Maps-Comparison-for-Endmember-Algorithms)\n",
    "            2. [Abundance Maps Comparison for Abundance Maps Algorithms](#Abundance-Maps-Comparison-for-Abundance-Maps-Algorithms)\n",
    "            3. [Abundance Maps Comparison for Joint Algorithms](#Abundance-Maps-Comparison-for-Joint-Algorithms)\n",
    "        3. [External Algorithm Abundance Maps Comparison](#External-Algorithm-Abundance-Maps-Comparison)\n",
    "            1. [Abundance Maps Comparison for Endmember Algorithms vs. Abundance Maps Algorithms](#Abundance-Maps-Comparison-for-Endmember-Algorithms-vs.-Abundance-Maps-Algorithms)\n",
    "            2. [Abundance Maps Comparison for Endmember Algorithms vs. Joint Algorithms](#Abundance-Maps-Comparison-for-Endmember-Algorithms-vs.-Joint-Algorithms)\n",
    "            3. [Abundance Maps Comparison for Abundance Maps Algorithms vs. Joint Algorithms](#Abundance-Maps-Comparison-for-Abundance-Maps-Algorithms-vs.-Joint-Algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import operator\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import skimage\n",
    "import skimage.measure\n",
    "from skimage import io as skio\n",
    "\n",
    "from pysptools.abundance_maps.amaps import FCLS\n",
    "from pysptools.abundance_maps.amaps import NNLS\n",
    "\n",
    "import pysptools.abundance_maps\n",
    "import pysptools.distance\n",
    "import pysptools.eea\n",
    "\n",
    "## https://github.com/kimjingu/nonnegfac-python\n",
    "from nonnegfac import matrix_utils as mu\n",
    "from nonnegfac import nnls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter List\n",
    "\n",
    "## Documentation\n",
    "\n",
    "* `dirname`  \n",
    " The `dirname` variable specifies the location of the directory containing all data files used by this notebook.  This includes the HSI input data, ground truth data, and precomputed result files.  This is also the location that any computed result files are stored.\n",
    " \n",
    " \n",
    "* `data_filename`  \n",
    " The `data_filename` variable specifies the name of the file containing the HSI data.  This file is assumed to be a `npz` file.  The HSI data should be stored in the `data` variable as a $height\\times width\\times bands$ `ndarray`.  Optionally, labels associated with the image can be stored in the `labels` variable as a $height\\times width$ `ndarray`.  See [numpy.savez](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.savez.html) and [numpy.savez_compressed](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.savez_compressed.html#numpy.savez_compressed).\n",
    " \n",
    " \n",
    "* `n_endmembers`  \n",
    " The `n_endmembers` variable specifies the number of endmembers/abundance maps extracted by the various algorithms.\n",
    " \n",
    " \n",
    "* `n_neighbors`  \n",
    " The `n_neighbors` variable specifies the number of neighbors used by the local techniques (i.e., LLE).  Note that for *Hessian-based LLE*, `n_neighbors` must be greater than $n\\_endmembers * (n\\_endmembers + 3) / 2$.\n",
    " \n",
    " \n",
    "* `endmember_algorithms`  \n",
    " The `endmember_algorithms` variable should be a list specifying which *endmembers* extraction algorithms to include.  Any algorithm not present in this list is omitted.  Currently implemented options are `ATGP`, `FIPPI`, `N-FINDR`, and `PPI`.\n",
    " \n",
    " \n",
    "* `abundance_maps_algorithms`  \n",
    " The `abundance_maps_algorithms` variable should be a list specifying which *abundance maps* extraction algorithms to include.  Any algorithm not present in this list is omitted.  Currently implemented options are `ISOMAP`, `LLE`, `MLLE`, `HLLE`, `SE`, `LTSA`, `MMDS`, `NMDS`, and `TSNE`.\n",
    " \n",
    " \n",
    " * `joint_algorithms`  \n",
    " The `joint_algorithms` variable should be a list specifying which *joint unmixing algorithms* extraction algorithms to include.  Any algorithm not present in this list is omitted.  Currently implemented options are `PCA`, `NMF`, `Joint-NMF`, and `GR-NMF`.\n",
    " \n",
    " \n",
    "* `compute`  \n",
    " The `compute` variable determines whether precomputed values are used or ignored.  If `compute==\"cache_only\"`, only precomputed results will be used.  If `compute==\"recompted\"`, all results will be compted and no precomputed results will be used.  If `compute==\"auto\"`, results will be compted as needed and precomputed results will be use if avaliable.\n",
    " \n",
    " \n",
    "* `save_results`  \n",
    " The `save_results` variable determines whether results computed during notebook execution are saved and available for use as precomputed results on subsequent runs.  If `save_results` is `True`, any results computed are saved.\n",
    " \n",
    " \n",
    "* `endmember_comp`  \n",
    " The `endmember_comp` variable specifies the function to use when comparing endmembers.  [PySptools](https://pysptools.sourceforge.io/distance.html) and [SciPi](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html) have a variety of functions for vectors (i.e., endmembers) that can be used.  Alternatively, any function that accepts two arguments and returns a `float` can be used.\n",
    "\n",
    "\n",
    "* `abundance_maps_comp`  \n",
    " The `abundance_maps_comp` variable specifies the function to use when comparing abundance maps.  [SciPi](http://scikit-image.org/docs/dev/api/skimage.measure.html) has a few functions for comparing images (i.e., abundance maps) that can be used.  Alternatively, any function that accepts two arguments and returns a `float` can be used.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indian-pines dataset\n",
    "dirname = \"../sample-data/indian-pines\"\n",
    "data_filename = \"data.npz\"\n",
    "n_endmembers = 5\n",
    "\n",
    "## jasper dataset\n",
    "#dirname = \"../sample-data/jasper-ridge\"\n",
    "#data_filename = \"data.npz\"\n",
    "#ground_truth_filename = \"ground-truth.npz\"\n",
    "#n_endmembers = 4\n",
    "\n",
    "endmember_algorithms = [\"ATGP\", \"FIPPI\", \"N-FINDR\", \"PPI\"]\n",
    "abundance_maps_algorithms = [\"ISOMAP\", \"LLE\", \"MLLE\", \"HLLE\", \"SE\", \"LTSA\", \"MMDS\", \"NMDS\", \"TSNE\"]\n",
    "joint_algorithms = [\"PCA\", \"NMF\", \"Joint-NMF\", \"GR-NMF\"]\n",
    "\n",
    "# n_neighbors must be greater than\n",
    "# (n_endmembers * (n_endmembers + 3) / 2) for Hessian-based LLE \n",
    "n_neighbors = (n_endmembers * (n_endmembers + 3) / 2) + 1\n",
    "\n",
    "compute = \"cache_only\"\n",
    "\n",
    "save_results = True\n",
    "\n",
    "#abundance_maps_comp = skimage.measure.compare_mse    # Mean Squared Error (MSE)\n",
    "#abundance_maps_comp = skimage.measure.compare_nrmse  # Normalized Root Mean-Squared Error (NRMSE)\n",
    "#abundance_maps_comp = skimage.measure.compare_psnr   # Peak Signal to Noise Ratio (PSNR)\n",
    "abundance_maps_comp = skimage.measure.compare_ssim   # Mean Structural Similarity (SSIM)\n",
    "\n",
    "#endmember_comp = spatial.distance.chebyshev    # Chebychev\n",
    "#endmember_comp = spatial.distance.cosine       # Cosine\n",
    "#endmember_comp = pysptools.distance.NormXCorr  # Normalized Cross Correlation\n",
    "#endmember_comp = spatial.distance.euclidean    # Euclidean\n",
    "endmember_comp = pysptools.distance.SAM        # Spectral Angle Mapper\n",
    "#endmember_comp = pysptools.distance.SID        # Spectral Information Divergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables\n",
    "<span style=\"color:red\">These variables are used throughout the notebook and should not be modified.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_maps_dict = {}\n",
    "endmembers_dict = {}\n",
    "\n",
    "algorithms = endmember_algorithms + abundance_maps_algorithms + joint_algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_hsi_data(filename):\n",
    "    with np.load( filename ) as npz_file:\n",
    "        expected_fields = [\"data\", \"labels\"]\n",
    "        unexpected_fileds = [name for name in npz_file.files if name not in expected_fields]\n",
    "        if unexpected_fileds:\n",
    "            message = \"ignoring unexpected fileds in '{}': {}\"\n",
    "            message = message.format(filename, \", \".join(unexpected_fileds))\n",
    "            print >> sys.stderr, message\n",
    "            \n",
    "        hsi_3d = npz_file[\"data\"]\n",
    "        if len(hsi_3d.shape) != 3:\n",
    "            raise TypeError(\"Image must have size height x width x bands\")\n",
    "\n",
    "        if \"labels\" in npz_file.files:\n",
    "            labels = npz_file[\"labels\"]\n",
    "            if len(labels.shape) != 2:\n",
    "                raise TypeError(\"Labels must have size height x width\")\n",
    "            elif hsi_3d.shape[:-1] != labels.shape:\n",
    "                message = \"Image and label dimensions do not mach: {} {}\"\n",
    "                message = message.format(hsi_3d.shape, labels.shape)\n",
    "                raise TypeError(message)\n",
    "        else:\n",
    "            labels = None\n",
    "    return hsi_3d, labels \n",
    "\n",
    "def read_ground_truth(filename, hsi_3d):\n",
    "    hsi_2d = np.reshape(hsi_3d, (hsi_3d.shape[0]*hsi_3d.shape[1], hsi_3d.shape[2]))\n",
    "    image_dim = (hsi_3d.shape[0], hsi_3d.shape[1])\n",
    "    spectrial_len = hsi_3d.shape[2]\n",
    "    \n",
    "    with np.load( filename ) as npz_file:\n",
    "        expected_fields = [\"abundance_maps\", \"endmembers\"]\n",
    "        unexpected_fileds = [name for name in npz_file.files if name not in expected_fields]\n",
    "        if unexpected_fileds:\n",
    "            message = \"ignoring unexpected fileds in '{}': {}\"\n",
    "            message = message.format(ground_truth_filename, \", \".join(unexpected_fileds))\n",
    "            print >> sys.stderr, message\n",
    "        \n",
    "        if \"abundance_maps\" in npz_file.files or \"endmembers\" in npz_file.files:\n",
    "            if \"abundance_maps\" in npz_file.files:\n",
    "                abundance_maps = npz_file[\"abundance_maps\"]\n",
    "                if abundance_maps.shape[1:3] != image_dim:\n",
    "                    message = \"data image size does not match ground truth image size: {} {}\"\n",
    "                    message = message.format(hsi_3d.shape, abundance_maps.shape)\n",
    "                    raise TypeError(message)\n",
    "\n",
    "            if \"endmembers\" in npz_file.files:\n",
    "                endmembers = npz_file[\"endmembers\"]\n",
    "                if endmembers.shape[1] != spectrial_len:\n",
    "                    message = \"data spectrum does not mach ground truth spectrum: {} {}\"\n",
    "                    message = message.format(hsi_3d.shape, endmembers.shape)\n",
    "                    raise TypeError(message)\n",
    "\n",
    "            if \"abundance_maps\" not in npz_file.files:\n",
    "                message = \"ground truth abundance maps not provided, estimating with NNLS\"\n",
    "                print >> sys.stderr, message\n",
    "                #abundance_maps = FCLS(hsi_2d, endmembers)\n",
    "                abundance_maps = NNLS(hsi_2d, endmembers)\n",
    "                abundance_maps = preprocessing.normalize(abundance_maps, norm=\"l1\")\n",
    "                abundance_maps = np.reshape(abundance_maps, (hsi_3d.shape[0], hsi_3d.shape[1], abundance_maps.shape[1]))\n",
    "                abundance_maps = np.moveaxis(abundance_maps, 2, 0)\n",
    "            elif \"endmembers\" not in npz_file.files:\n",
    "                message = \"ground truth endmembers not provided, estimating with NNLS\"\n",
    "                print >> sys.stderr, message\n",
    "                print abundance_maps.shape\n",
    "                tmp_maps = np.moveaxis(abundance_maps, 0, 2)\n",
    "                print tmp_maps.shape\n",
    "                tmp_maps = np.reshape(tmp_maps, (tmp_maps.shape[0]*tmp_maps.shape[1],tmp_maps.shape[2]))\n",
    "                print tmp_maps.shape \n",
    "                endmembers = NNLS(hsi_2d.transpose(), \n",
    "                                  tmp_maps.transpose())\n",
    "                endmembers = endmembers.transpose()\n",
    "                print endmembers.shape\n",
    "            elif abundance_maps.shape[0] != endmembers.shape[0]:\n",
    "                message = \"number of abundance maps ({}) does not match associated endmembers ({})\"\n",
    "                message = message.format(abundance_maps.shape, endmembers.shape)\n",
    "                print >> sys.stderr, message\n",
    "                \n",
    "        else:\n",
    "            message = \"No ground truth data found in '{}'\"\n",
    "            message = message.format(ground_truth_filename)\n",
    "            raise RuntimeError(message)\n",
    "    return endmembers, abundance_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Reading / Writing Precomputed Results\n",
    "\n",
    "Results for any of the algorithms can be precomputed and stored within the directory specified by `dirname`.  File names are assumed to have a format of `{algorithm}.{n_endmembers}.npz`, where `algorithm` is the lowercase abreviation of an algorithm and `n_endmembers` is the number of endmembers captured by the results.\n",
    "\n",
    "The `.npz` file containg precomputed results must contain **_both_** the endmembers and abundance maps.  The _abundance maps_ should be saved as a $height\\times width\\times n\\_endmembers$ `ndarray` using the key `abundance_maps`.  The _endmembers_ should be saved as a $n\\_endmembers \\times spectrial\\_bands$ `ndarray` using the key `endmembers`.\n",
    "* https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.savez.html\n",
    "* https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.savez_compressed.html#numpy.savez_compressed\n",
    "* https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.load.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(filename):\n",
    "    with np.load(filename) as npz_file:\n",
    "        unexpected_fileds = [field for field in npz_file.files if field not in [\"endmembers\", \"abundance_maps\"]]\n",
    "        \n",
    "        if unexpected_fileds:\n",
    "            message = \"ignoring unexpected fileds in '{}': {}\"\n",
    "            message = message.format(filename, \", \".join(unexpected_fileds))\n",
    "            print >> sys.stderr, message\n",
    "        \n",
    "        endmembers = npz_file[\"endmembers\"]\n",
    "        abundance_maps = npz_file[\"abundance_maps\"]\n",
    "        \n",
    "        return endmembers, abundance_maps\n",
    "\n",
    "def write_results(filename, endmembers, abundance_maps):\n",
    "    np.savez(filename,\n",
    "             endmembers=endmembers,\n",
    "             abundance_maps=abundance_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Classes for Running PySptool Algorithms\n",
    "https://pysptools.sourceforge.io/eea.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PYSP_Extractor(object):\n",
    "    ALGORITHM = None\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_components(self, hsi_3d, n_endmembers):\n",
    "        hsi_2d = np.reshape(hsi_3d, (hsi_3d.shape[0]*hsi_3d.shape[1],hsi_3d.shape[2]))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        endmembers = self.eea_algorithm.extract(hsi_3d, n_endmembers)\n",
    "        elapsed = time.time() - start_time\n",
    "        print self.ALGORITHM, \"Computation Time:\", timedelta(seconds=elapsed)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        #abundance_maps = FCLS(hsi_2d, endmembers)\n",
    "        abundance_maps = NNLS(hsi_2d, endmembers)\n",
    "        elapsed = time.time() - start_time\n",
    "        print self.ALGORITHM, \"Abundance Map Estimation Time:\", timedelta(seconds=elapsed)\n",
    "        \n",
    "        abundance_maps = preprocessing.normalize(abundance_maps, norm=\"l1\")\n",
    "        abundance_maps = np.moveaxis(abundance_maps, 1, 0)\n",
    "        abundance_maps = np.reshape(abundance_maps, (abundance_maps.shape[0], hsi_3d.shape[0], hsi_3d.shape[1]))\n",
    "        return endmembers, abundance_maps\n",
    "\n",
    "class ATGP_Extractor(PYSP_Extractor):\n",
    "    ALGORITHM = \"ATGP\"\n",
    "    def __init__(self):\n",
    "        self.eea_algorithm = pysptools.eea.ATGP()\n",
    "        super(ATGP_Extractor, self).__init__()\n",
    "\n",
    "class FIPPI_Extractor(PYSP_Extractor):\n",
    "    ALGORITHM = \"FIPPI\"\n",
    "    def __init__(self):\n",
    "        self.eea_algorithm = pysptools.eea.FIPPI()\n",
    "        super(FIPPI_Extractor, self).__init__()\n",
    "\n",
    "class NFINDR_Extractor(PYSP_Extractor):\n",
    "    ALGORITHM = \"N-FINDR\"\n",
    "    def __init__(self):\n",
    "        self.eea_algorithm = pysptools.eea.NFINDR()\n",
    "        super(NFINDR_Extractor, self).__init__()\n",
    "\n",
    "class PPI_Extractor(PYSP_Extractor):\n",
    "    ALGORITHM = \"PPI\"\n",
    "    def __init__(self):\n",
    "        self.eea_algorithm = pysptools.eea.PPI()\n",
    "        super(PPI_Extractor, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Classes for Running scikit-learn Algorithms\n",
    "http://scikit-learn.org/stable/modules/manifold.html  \n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SKLEARN_Extractor(object):\n",
    "    ALGORITHM = None\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_components(self, hsi_3d, n_endmembers):\n",
    "        hsi_2d = np.reshape(hsi_3d, (hsi_3d.shape[0]*hsi_3d.shape[1],hsi_3d.shape[2]))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        abundance_maps = self.mfld_obj.fit_transform(hsi_2d)\n",
    "        elapsed = time.time() - start_time\n",
    "        print self.ALGORITHM, \"Computation Time:\", timedelta(seconds=elapsed)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        endmembers = NNLS(hsi_2d.transpose(), abundance_maps.transpose())\n",
    "        elapsed = time.time() - start_time\n",
    "        print self.ALGORITHM, \"Abundance Map Estimation Time:\", timedelta(seconds=elapsed)\n",
    "        \n",
    "        abundance_maps = np.moveaxis(abundance_maps, 1, 0)\n",
    "        abundance_maps = np.reshape(abundance_maps, (abundance_maps.shape[0], hsi_3d.shape[0], hsi_3d.shape[1]))\n",
    "        endmembers = endmembers.transpose()\n",
    "        return endmembers, abundance_maps    \n",
    "\n",
    "class ISOMAP_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"ISOMAP\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.Isomap(n_neighbors=n_neighbors, n_components=n_components, n_jobs=n_jobs)\n",
    "        super(ISOMAP_Extractor, self).__init__()\n",
    "\n",
    "class LLE_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"LLE\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, method=\"standard\", n_jobs=-1)\n",
    "        super(LLE_Extractor, self).__init__()\n",
    "\n",
    "class MLLE_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"MLLE\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, method=\"modified\", n_jobs=n_jobs)\n",
    "        super(MLLE_Extractor, self).__init__()\n",
    "\n",
    "class HLLE_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"HLLE\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, method=\"hessian\", eigen_solver=\"dense\", n_jobs=n_jobs)\n",
    "        super(HLLE_Extractor, self).__init__()\n",
    "\n",
    "class SE_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"SE\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.SpectralEmbedding(n_neighbors=n_neighbors, n_components=n_components, n_jobs=n_jobs)\n",
    "        super(SE_Extractor, self).__init__()\n",
    "\n",
    "class LTSA_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"LTSA\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.LocallyLinearEmbedding(n_neighbors=n_neighbors, n_components=n_components, method=\"ltsa\", n_jobs=n_jobs)\n",
    "        super(LTSA_Extractor, self).__init__()\n",
    "\n",
    "class MMDS_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"MMDS\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.MDS(n_components=n_components, metric=True, n_jobs=n_jobs)\n",
    "        super(MMDS_Extractor, self).__init__()\n",
    "\n",
    "class NMDS_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"NMDS\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.MDS(n_components=n_components, metric=False, n_jobs=n_jobs)\n",
    "        super(NMDS_Extractor, self).__init__()\n",
    "\n",
    "class TSNE_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"TSNE\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = manifold.TSNE(n_components=n_components, method=\"exact\")\n",
    "        super(TSNE_Extractor, self).__init__()\n",
    "\n",
    "class PCA_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"PCA\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = decomposition.PCA(n_components=n_components)\n",
    "        super(PCA_Extractor, self).__init__()\n",
    "\n",
    "class NMF_Extractor(SKLEARN_Extractor):\n",
    "    ALGORITHM = \"NMF\"\n",
    "    def __init__(self, n_components, n_neighbors, n_jobs=1):\n",
    "        self.mfld_obj = decomposition.NMF(n_components=n_components)\n",
    "        super(NMF_Extractor, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Classes for Running Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joint_Extractor(object):\n",
    "    ALGORITHM = None\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_components(self, hsi_3d, n_endmembers):\n",
    "        hsi_2d = np.reshape(hsi_3d, (hsi_3d.shape[0]*hsi_3d.shape[1], hsi_3d.shape[2]))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        endmembers, abundance_maps = self.joint_algorithm.extract(hsi_2d.T, n_endmembers)[0:2]\n",
    "        elapsed = time.time() - start_time\n",
    "        print self.ALGORITHM, \"Computation Time:\", timedelta(seconds=elapsed)\n",
    "        \n",
    "        endmembers = np.transpose(endmembers)\n",
    "        abundance_maps = np.reshape(abundance_maps, (hsi_3d.shape[0], hsi_3d.shape[1], n_endmembers))\n",
    "        abundance_maps = np.moveaxis(abundance_maps, 2, 0)\n",
    "        return endmembers, abundance_maps \n",
    "\n",
    "class JointNMF_Extractor(Joint_Extractor):\n",
    "    ALGORITHM = \"Joint-NMF\"\n",
    "    def __init__(self):\n",
    "        self.joint_algorithm = JointNMF()\n",
    "        super(JointNMF_Extractor, self).__init__()\n",
    "\n",
    "class GRNMF_Extractor(Joint_Extractor):\n",
    "    ALGORITHM = \"GR-NMF\"\n",
    "    def __init__(self):\n",
    "        self.joint_algorithm = GRNMF()\n",
    "        super(GRNMF_Extractor, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help Functions for Executing Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_components(extractor, hsi_3d, n_endmembers, results_filename=None, compute=\"auto\", save_results=True):\n",
    "    image_dim = hsi_3d.shape[0:2]\n",
    "    recompute = False\n",
    "    if compute != \"recompute\":\n",
    "        try:\n",
    "            endmembers, abundance_maps = read_results(results_filename)\n",
    "            expected_shape = (n_endmembers, hsi_3d.shape[-1])\n",
    "            if endmembers.shape != expected_shape:\n",
    "                message = \"Unexpected endmembers shape {}, expecting {}\"\n",
    "                message = message.format(endmembers.shape, expected_shape)\n",
    "                raise TypeError(message)\n",
    "            expected_shape = (n_endmembers, hsi_3d.shape[0], hsi_3d.shape[1])\n",
    "            if abundance_maps.shape != expected_shape:\n",
    "                message = \"Unexpected abundance maps shape {}, expecting {}\"\n",
    "                message = message.format(abundance_maps.shape, expected_shape)\n",
    "                raise TypeError(message)\n",
    "        except Exception as ex:\n",
    "            if compute != \"cache_only\":\n",
    "                print >> sys.stderr, ex\n",
    "                print >> sys.stderr, \"recomputing\", extractor.ALGORITHM\n",
    "                compute = \"recompute\"\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    if compute == \"recompute\":\n",
    "        endmembers, abundance_maps = extractor.get_components(hsi_3d, n_endmembers)\n",
    "        expected_shape = (n_endmembers, hsi_3d.shape[-1])\n",
    "        if endmembers.shape != expected_shape:\n",
    "            message = \"Unexpected endmembers shape {}, expecting {}\"\n",
    "            message = message.format(endmembers.shape, expected_shape)\n",
    "            print >> sys.stderr, message\n",
    "        expected_shape = (n_endmembers, hsi_3d.shape[0], hsi_3d.shape[1])\n",
    "        if abundance_maps.shape != expected_shape:\n",
    "            message = \"Unexpected abundance maps shape {}, expecting {}\"\n",
    "            message = message.format(abundance_maps.shape, expected_shape)\n",
    "            print >> sys.stderr, message\n",
    "        \n",
    "        if save_results:\n",
    "            write_results(results_filename,\n",
    "                         endmembers,\n",
    "                         abundance_maps)\n",
    "    return endmembers, abundance_maps\n",
    "            \n",
    "def run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, hsi_3d, compute=\"auto\", save_results=True):\n",
    "    basename = \"{}.{}.npz\".format(alg_name.lower(), n_endmembers)\n",
    "    results_filename = os.path.join(dirname, basename)\n",
    "    \n",
    "    pysp_algorithm = [ATGP_Extractor, FIPPI_Extractor, NFINDR_Extractor, PPI_Extractor]\n",
    "    for extractor in pysp_algorithm:\n",
    "        if extractor.ALGORITHM == alg_name:\n",
    "            return extract_components(extractor(), hsi_3d, n_endmembers, results_filename=results_filename, compute=compute, save_results=save_results)\n",
    "        \n",
    "    sklearn_algorithms = [ISOMAP_Extractor, LLE_Extractor, MLLE_Extractor, HLLE_Extractor, SE_Extractor, LTSA_Extractor, MMDS_Extractor, NMDS_Extractor, TSNE_Extractor, PCA_Extractor, NMF_Extractor]\n",
    "    for extractor in sklearn_algorithms:\n",
    "        if extractor.ALGORITHM == alg_name:\n",
    "            return extract_components(extractor(n_endmembers, n_neighbors), hsi_3d, n_endmembers, results_filename=results_filename, compute=compute, save_results=save_results)\n",
    "    \n",
    "    joint_algorithms = [JointNMF_Extractor, GRNMF_Extractor]\n",
    "    for extractor in joint_algorithms:\n",
    "        if extractor.ALGORITHM == alg_name:\n",
    "            return extract_components(extractor(), hsi_3d, n_endmembers, results_filename=results_filename, compute=compute, save_results=save_results)\n",
    "    JointNMF_Extractor\n",
    "    \n",
    "    message = \"Algorithm Not Implemented: {}\".format(alg_name)\n",
    "    raise NotImplementedError(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Displaying a HSI Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cube(data, top_band=None, top_cmap=plt.cm.jet, side_cmap=plt.cm.jet, elev=None, azim=-30):\n",
    "    top_cmap = plt.get_cmap(top_cmap)\n",
    "    side_cmap = plt.get_cmap(side_cmap)\n",
    "    \n",
    "    if top_band is None:\n",
    "        top_band= np.argmax(np.var(np.reshape(data, (-1, data.shape[2])), 0))\n",
    "\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    fig.suptitle(\"HSI Cube {}\".format(data.shape), fontsize=16)\n",
    "    ax = fig.gca(projection=\"3d\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_axis_off()\n",
    "    ax.view_init(elev, azim)\n",
    "\n",
    "    # X constant faces\n",
    "    YY, ZZ, = np.mgrid[0:data.shape[1], 0:data.shape[2]]\n",
    "    XX = np.zeros(YY.shape)\n",
    "    #ax.plot_surface(XX, YY, ZZ, shade=False, facecolors=side_cmap(plt.Normalize()(data[0,:,:])))\n",
    "    XX += data.shape[0]-1\n",
    "    ax.plot_surface(XX, YY, ZZ, shade=False, facecolors=side_cmap(plt.Normalize()(data[-1,:,:])))\n",
    "\n",
    "    # Y constant faces\n",
    "    XX, ZZ, = np.mgrid[0:data.shape[0], 0:data.shape[2]]\n",
    "    YY = np.zeros(XX.shape)\n",
    "    ax.plot_surface(XX, YY, ZZ, shade=False, facecolors=side_cmap(plt.Normalize()(data[:,0,:])))\n",
    "    YY += data.shape[1]-1\n",
    "    #ax.plot_surface(XX, YY, ZZ, shade=False, facecolors=side_cmap(plt.Normalize()(data[:,-1,:])))\n",
    "\n",
    "    # Z constant faces\n",
    "    XX, YY, = np.mgrid[0:data.shape[0], 0:data.shape[1]]\n",
    "    ZZ = np.zeros(XX.shape)\n",
    "    #ax.plot_surface(XX, YY, ZZ, shade=False, facecolors=side_cmap(plt.Normalize()(data[:,:,0])))\n",
    "    ZZ += data.shape[2]-1\n",
    "    ax.plot_surface(XX, YY, ZZ, shade=False, facecolors=top_cmap(plt.Normalize()(data[:,:,top_band])))\n",
    "    \n",
    "    # Create cubic bounding box to simulate equal aspect ratio\n",
    "    max_range = np.max(data.shape)\n",
    "    Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(data.shape[0])\n",
    "    Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(data.shape[1])\n",
    "    Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(data.shape[0])\n",
    "    # Comment or uncomment following both lines to test the fake bounding box:\n",
    "    for xb, yb, zb in zip(Xb, Yb, Zb):\n",
    "        ax.plot([xb], [yb], [zb], 'w')\n",
    "\n",
    "    plt.tight_layout(0, 0, 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Displaying Endmembers and Abundance Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_components(endmembers, abundance_maps, alg_name=None, vmin=0.0, vmax=None, cmap=\"jet\"):\n",
    "    if endmembers is not None and abundance_maps is not None:\n",
    "        if endmembers.shape[0] != abundance_maps.shape[0]:\n",
    "            message = \"Endmember count ({}) and abundance map count ({}) must match.\"\n",
    "            message = message.format(endmembers.shape, abundance_maps.shape)\n",
    "            raise ValueError(message)\n",
    "        n_components = endmembers.shape[0]\n",
    "        n_cols = 2\n",
    "    else:\n",
    "        if endmembers is not None:\n",
    "            n_components = endmembers.shape[0]\n",
    "        elif abundance_maps is not None:\n",
    "            n_components = abundance_maps.shape[0]\n",
    "        else:\n",
    "            raise ValueError(\"Both endmembers and abundance_maps cannot be None.\")\n",
    "        n_cols = 1\n",
    "    \n",
    "    if endmembers is not None:\n",
    "        if alg_name is not None:\n",
    "            title = \"{} - Endmembers\".format(alg_name)\n",
    "        else:\n",
    "            title = \"Endmembers\".format(alg_name)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Wavelength\")\n",
    "        plt.ylabel(\"Brightness\")\n",
    "        lines = plt.plot(endmembers.transpose())\n",
    "        plt.show()\n",
    "    \n",
    "    for index in xrange(n_components):\n",
    "        fig = plt.figure(figsize = (8,3))\n",
    "        gs = mpl.gridspec.GridSpec(1, n_cols)\n",
    "        \n",
    "        if alg_name is not None:\n",
    "            title = \"{} - Component {}\".format(alg_name, index)\n",
    "        else:\n",
    "            title = \"Component {}\".format(index)\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "        \n",
    "        if endmembers is not None:\n",
    "            ax = fig.add_subplot(gs[0,0])\n",
    "            ax.set_xlabel(\"Wavelength\")\n",
    "            ax.set_ylabel(\"Brightness\")\n",
    "            ax.plot(endmembers[index,:], lines[index].get_color())\n",
    "        \n",
    "        if abundance_maps is not None:\n",
    "            ax = fig.add_subplot(gs[0,n_cols-1])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            im = ax.imshow(abundance_maps[index,:,:], vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "            fig.colorbar(im, ax=ax)\n",
    "        \n",
    "        #plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "        plt.show()\n",
    "        \n",
    "#display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Displaying a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_matrix(matrix, xlabel=None, xticks=None, ylabel=None, yticks=None, floatfmt=\"0.4f\", cmap=\"binary\", title=None, figsize=None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    #labelbottom, labeltop, labelleft, labelright\n",
    "    labelbottom = True\n",
    "    labelleft = True\n",
    "    \n",
    "    if xlabel is not None:\n",
    "        labelbottom=False\n",
    "        ax.set_xlabel(xlabel)\n",
    "    if xticks is None:\n",
    "        xticks = range(matrix.shape[1])\n",
    "    ax.set_xticklabels([\"\"]+xticks)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    if ylabel is not None:\n",
    "        labelleft=False\n",
    "        ax.set_ylabel(ylabel)\n",
    "    if yticks is None:\n",
    "        yticks = range(matrix.shape[0])\n",
    "    ax.set_yticklabels([\"\"]+yticks)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title, y=1.08)\n",
    "            \n",
    "    #ax.tick_params(axis=\"both\", which=\"both\", labelbottom=labelbottom, labeltop=True, labelleft=labelleft, labelright=True, length=0)\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", labelbottom=True, labeltop=True, labelleft=True, labelright=True, length=0)\n",
    "    \n",
    "    im = ax.imshow(matrix, interpolation=\"nearest\", cmap=cmap)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    \n",
    "    threshold = (matrix.max()-matrix.min()) / 2. + matrix.min()\n",
    "    for ii, jj in itertools.product(xrange(matrix.shape[0]), xrange(matrix.shape[1])):\n",
    "        text = format(matrix[ii,jj], floatfmt)\n",
    "        if matrix[ii,jj] > threshold:\n",
    "            color = \"white\"\n",
    "        else:\n",
    "            color = \"black\"\n",
    "        plt.text(jj, ii, text, horizontalalignment=\"center\", color=color)\n",
    "    #plt.savefig(\"{}-vs-{}.mat.png\".format(ylabel, xlabel), format=\"png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Matching Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _possible_endmember_metric(endmembers, metric):\n",
    "    size = endmembers.shape[0]\n",
    "    diag = np.zeros(size)\n",
    "    for index in xrange(size):\n",
    "        diag[index] = metric(endmembers[index,:], endmembers[index,:])\n",
    "    res = np.max( diag[np.isfinite(diag)] )\n",
    "    return np.isclose(res, 0.0, atol=1e-07)\n",
    "\n",
    "def _possible_abundance_maps_metric(abundance_maps, metric):\n",
    "    size = abundance_maps.shape[0]\n",
    "    diag = np.zeros(size)\n",
    "    for index in xrange(size):\n",
    "        diag[index] = metric(abundance_maps[index,:,:], abundance_maps[index,:,:])\n",
    "    res = np.max( diag[np.isfinite(diag)] )\n",
    "    return np.isclose(res, 0.0, atol=1e-07)\n",
    "\n",
    "def _match_best(distances, metric=True):\n",
    "    if metric:\n",
    "        distances[np.isnan(distances)] = np.finfo(distances.dtype).max\n",
    "        fun = np.argmin\n",
    "    else:\n",
    "        distances[np.isnan(distances)] = np.finfo(distances.dtype).min\n",
    "        fun = np.argmax\n",
    "    matches = [fun(distances[ii,:]) for ii in xrange(distances.shape[0])]\n",
    "    return matches\n",
    "\n",
    "def _pair_greedy(distances, metric=True):\n",
    "    mean = np.nanmean(distances)\n",
    "    distances = np.copy(distances)\n",
    "    if metric:\n",
    "        distances[np.isnan(distances)] = np.finfo(distances.dtype).max\n",
    "        fun = np.nanargmin\n",
    "        compare = operator.lt\n",
    "    else:\n",
    "        distances[np.isnan(distances)] = np.finfo(distances.dtype).min\n",
    "        fun = np.nanargmax\n",
    "        compare = operator.gt\n",
    "    \n",
    "    matches = [-1] * distances.shape[0]\n",
    "    n_iter = np.min(distances.shape)\n",
    "    for ii in xrange(n_iter):\n",
    "        loc = np.unravel_index(fun(distances), distances.shape)\n",
    "        if compare(distances[loc], mean):\n",
    "            matches[loc[0]] = loc[1]\n",
    "        distances[loc[0],:] = np.nan\n",
    "        distances[:,loc[1]] = np.nan\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Comparing Endmembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compare_endmembers(endmembers1, endmembers2, algorithm1=\"Endmembers1\", algorithm2=\"Endmembers2\", metric=pysptools.distance.SAM, matrix_vmin=0.0, matrix_vmax=None, matrix_cmap=None, floatfmt=\"0.4f\", match_fun=_pair_greedy, is_metric=None):\n",
    "    try:\n",
    "        if is_metric is None:\n",
    "            is_metric = _possible_endmember_metric(endmembers1, metric)\n",
    "    except Exception as ex:\n",
    "        print >> sys.stderr, \"Test for metric failed:\", str(ex)\n",
    "    \n",
    "    distances = spatial.distance.cdist(endmembers1, endmembers2, metric=metric)\n",
    "    if match_fun is None or is_metric is None:\n",
    "        matches = [-1] * distances.shape[0]\n",
    "    else:\n",
    "        matches = match_fun(distances, is_metric)\n",
    "    \n",
    "    # https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html\n",
    "    markers = mpl.lines.Line2D.filled_markers\n",
    "    c1 = [None] * distances.shape[0]\n",
    "    c2 = [None] * distances.shape[1]\n",
    "    for index,match in enumerate(matches):\n",
    "        if match != -1:\n",
    "            if c2[match] == None:\n",
    "                c2[match] = {\"color\":\"C{}\".format(index), \"marker\":markers[index], \"markevery\":0.75}\n",
    "            c1[index] = c2[match]\n",
    "    default_args = {\"color\":\"black\", \"linestyle\":\"dotted\"}\n",
    "    for index,match in enumerate(c1):\n",
    "        if match is None:\n",
    "            c1[index] = default_args\n",
    "    for index,match in enumerate(c2):\n",
    "        if match is None:\n",
    "            c2[index] = default_args\n",
    "        \n",
    "    if matrix_cmap is None:\n",
    "        if is_metric is None:\n",
    "            matrix_cmap = \"binary\"\n",
    "        elif is_metric:\n",
    "            matrix_cmap = \"YlOrRd\"\n",
    "        else:\n",
    "            matrix_cmap = \"Greens\"\n",
    "    \n",
    "    columns = max(endmembers1.shape[0], endmembers2.shape[0])\n",
    "    \n",
    "    alg1_max = np.max(endmembers1)\n",
    "    alg2_max = np.max(endmembers2)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    fig.suptitle(\"{} vs. {}\".format(algorithm1, algorithm2), size=20)\n",
    "    \n",
    "    gs = mpl.gridspec.GridSpec(2, columns)\n",
    "    for col in xrange(columns):\n",
    "        if endmembers1.shape[0] > col:\n",
    "            endmember = endmembers1[col,:]\n",
    "            ax = fig.add_subplot(gs[0,col])\n",
    "            ax.set_title(\"{} - EM {}\".format(algorithm1, col))\n",
    "            ax.set_xticks([])\n",
    "            if col != 0:\n",
    "                ax.set_yticks([])\n",
    "            ax.set_ylim([0.0,alg1_max])\n",
    "            ax.plot(endmember, **c1[col])\n",
    "        \n",
    "        if endmembers2.shape[0] > col:\n",
    "            endmember = endmembers2[col,:]\n",
    "            ax = fig.add_subplot(gs[1,col])\n",
    "            ax.set_title(\"{} - EM {}\".format(algorithm2, col))\n",
    "            ax.set_xticks([])\n",
    "            if col != 0:\n",
    "                ax.set_yticks([])\n",
    "            ax.set_ylim([0.0,alg2_max])\n",
    "            ax.plot(endmember, **c2[col])\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "    #plt.savefig(\"{}-vs-{}.em.fig.png\".format(algorithm1, algorithm2), format=\"png\")\n",
    "    plt.show()\n",
    "    \n",
    "    _display_matrix(distances, xlabel=algorithm2, ylabel=algorithm1, title=metric.__name__, cmap=matrix_cmap)\n",
    "    print tabulate(distances, tablefmt=\"grid\", floatfmt=floatfmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Comparing Abundance Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compare_abundance_maps(abundance_maps1, abundance_maps2, algorithm1=\"AbundanceMaps1\", algorithm2=\"AbundanceMaps2\", metric=skimage.measure.compare_ssim, abundance_cmap=\"jet\", matrix_cmap=None, floatfmt=\"0.4f\", match_fun=_pair_greedy, is_metric=None):\n",
    "    try:\n",
    "        if is_metric is None:\n",
    "            is_metric = _possible_abundance_maps_metric(abundance_maps1, metric)\n",
    "    except Exception as ex:\n",
    "        print >> sys.stderr, \"Test for metric failed:\", str(ex)\n",
    "    \n",
    "    rows = abundance_maps1.shape[0]\n",
    "    columns = abundance_maps2.shape[0]\n",
    "    distances = np.zeros(shape=(rows, columns))\n",
    "    for row in xrange(rows):\n",
    "        for col in xrange(columns):\n",
    "            distances[row,col] = metric(abundance_maps1[row,:,:], abundance_maps2[col,:,:])\n",
    "            \n",
    "    if match_fun is None or is_metric is None:\n",
    "        matches = [-1] * distances.shape[0]\n",
    "    else:\n",
    "        matches = match_fun(distances, is_metric)\n",
    "            \n",
    "    # https://matplotlib.org/api/text_api.html#matplotlib.text.Text\n",
    "    c1 = [None] * distances.shape[0]\n",
    "    c2 = [None] * distances.shape[1]\n",
    "    for index,match in enumerate(matches):\n",
    "        if match != -1:\n",
    "            if c2[match] == None:\n",
    "                c2[match] = {\"backgroundcolor\":\"C{}\".format(index)}\n",
    "            c1[index] = c2[match]\n",
    "    default_args = {}\n",
    "    for index,match in enumerate(c1):\n",
    "        if match is None:\n",
    "            c1[index] = default_args\n",
    "    for index,match in enumerate(c2):\n",
    "        if match is None:\n",
    "            c2[index] = default_args\n",
    "    \n",
    "    if matrix_cmap is None:\n",
    "        if is_metric is None:\n",
    "            matrix_cmap = \"binary\"\n",
    "        elif is_metric:\n",
    "            matrix_cmap = \"YlOrRd\"\n",
    "        else:\n",
    "            matrix_cmap = \"Greens\"\n",
    "            \n",
    "    columns = max(abundance_maps1.shape[0], abundance_maps2.shape[0])\n",
    "    \n",
    "    alg1_max = np.max( abundance_maps1 )\n",
    "    alg2_max = np.max( abundance_maps2 )\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    fig.suptitle(\"{} vs. {}\".format(algorithm1, algorithm2), size=20)\n",
    "    \n",
    "    #https://stackoverflow.com/questions/44837082/colorbar-for-each-row-in-imagegrid\n",
    "    TopGrid = ImageGrid(fig, 211,\n",
    "                nrows_ncols=(1,columns),\n",
    "                axes_pad=0.5,\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"single\",\n",
    "                cbar_size=\"10%\",\n",
    "                cbar_pad=0.2,\n",
    "                )\n",
    "    BottomGrid = ImageGrid(fig, 212,\n",
    "                nrows_ncols=(1,columns),\n",
    "                axes_pad=0.5,\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"single\",\n",
    "                cbar_size=\"10%\",\n",
    "                cbar_pad=0.2,\n",
    "                )\n",
    "    \n",
    "    for col in xrange(columns):\n",
    "        if abundance_maps1.shape[0] > col:\n",
    "            abundance_map = abundance_maps1[col,:,:]\n",
    "            \n",
    "            ax = TopGrid[col]\n",
    "            ax.set_title(\"{} - AM {}\".format(algorithm1, col), **c1[col])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            im = ax.imshow(abundance_map, vmin=0.0, vmax=alg1_max, cmap=abundance_cmap)\n",
    "            ax.cax.colorbar(im)\n",
    "            \n",
    "            \"\"\"if c1 is not None and False:\n",
    "                for spine in ax.spines.values():\n",
    "                    spine.set_edgecolor(c1[col])\n",
    "                    spine.set_position((\"outward\", 3))\n",
    "                    spine.set_linewidth(6)\"\"\"\n",
    "        \n",
    "        if abundance_maps2.shape[0] > col:\n",
    "            abundance_map = abundance_maps2[col,:,:]\n",
    "            \n",
    "            ax = BottomGrid[col]\n",
    "            ax.set_title(\"{0} - AM {1}\".format(algorithm2, col), **c2[col])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            im = ax.imshow(abundance_map, vmin=0.0, vmax=alg2_max, cmap=abundance_cmap)\n",
    "            ax.cax.colorbar(im)\n",
    "            \n",
    "            \"\"\"if c2 is not None:\n",
    "                for spine in ax.spines.values():\n",
    "                    spine.set_edgecolor(c2[col])\n",
    "                    spine.set_position((\"outward\", 3))\n",
    "                    spine.set_linewidth(6)\"\"\"\n",
    "            \n",
    "    #fig.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
    "    #plt.savefig(\"{}-vs-{}.am.fig.png\".format(algorithm1, algorithm2), format=\"png\")\n",
    "    plt.show()\n",
    "    \n",
    "    _display_matrix(distances, xlabel=algorithm2, ylabel=algorithm1, title=metric.__name__, cmap=matrix_cmap)\n",
    "    print tabulate(distances, tablefmt=\"grid\", floatfmt=floatfmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint NMF Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointNMF(object):\n",
    "    \"\"\"\n",
    "    solves min_W>=0,H>=0,H_hat>=0 ||A-WH.T||_F^2 + alpha * ||S-H_hat*H.T||_F^2 +\n",
    "                                   beta * ||H_hat - H||_F^2\n",
    "    Equation 8 in paper https://arxiv.org/pdf/1703.09646.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_iter=100, alpha=0.1, beta=1):\n",
    "        self.max_iter = max_iter\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def extract(self, A, k, W=None, H=None):\n",
    "        \"\"\" Run a NMF algorithm\n",
    "                Parameters\n",
    "                ----------\n",
    "                A : numpy.array or scipy.sparse matrix, shape (m,n)\n",
    "                m : Number of features\n",
    "                n : Number of samples\n",
    "                k : int - target lower rank\n",
    "                Returns\n",
    "                -------\n",
    "                (W, H, rec)\n",
    "                W : Obtained factor matrix, shape (m,k)\n",
    "                H : Obtained coefficient matrix, shape (n,k)\n",
    "        \"\"\"\n",
    "        if W is None and H is None:\n",
    "            W = np.random.rand(A.shape[0], k)\n",
    "            H = np.random.rand(A.shape[1], k)\n",
    "        elif W is None:\n",
    "            Sol, info = nnls.nnlsm_blockpivot(H, A.T)\n",
    "            W = Sol.T\n",
    "        elif H is None:\n",
    "            Sol, info = nnls.nnlsm_blockpivot(W.T, A)\n",
    "            H = Sol.T    \n",
    "        H_hat = np.random.rand(A.shape[1], k)\n",
    "        S = metrics.pairwise_kernels(A.T)\n",
    "        norm_A = mu.norm_fro(A)\n",
    "        for i in range(1, self.max_iter + 1):\n",
    "            (W, H, H_hat) = self.iter_solver(A, S, W, H, H_hat, self.alpha, self.beta)\n",
    "            rel_error = mu.norm_fro_err(A, W, H, norm_A) / norm_A\n",
    "        return W, H, H_hat\n",
    "\n",
    "    def iter_solver(self, A, S, W, H, H_hat, alpha, beta):\n",
    "        # equation 9 in paper https://arxiv.org/pdf/1703.09646.pdf\n",
    "        Sol, info = nnls.nnlsm_blockpivot(H, A.T, init=W.T)\n",
    "        W = Sol.T\n",
    "        # equation 10 in paper https://arxiv.org/pdf/1703.09646.pdf\n",
    "        tmp = np.sqrt(beta) * np.identity(H.shape[1])\n",
    "        lhs = np.concatenate((np.sqrt(alpha) * H, tmp))\n",
    "        tmp = np.sqrt(beta)*H\n",
    "        rhs = np.concatenate((np.sqrt(alpha)*S, tmp.T))\n",
    "        Sol, info = nnls.nnlsm_blockpivot(lhs, rhs)\n",
    "        H_hat = Sol.T\n",
    "        # equation 11 in paper https://arxiv.org/pdf/1703.09646.pdf\n",
    "        tmp_1 = np.sqrt(alpha) * H_hat\n",
    "        tmp_2 = np.sqrt(beta) * np.identity(H.shape[1])\n",
    "        lhs = np.concatenate((W, tmp_1, tmp_2))\n",
    "        tmp_1 = np.sqrt(alpha)*S\n",
    "        tmp_2 = np.sqrt(beta) * H_hat.T\n",
    "        rhs = np.concatenate((A, tmp_1, tmp_2))\n",
    "        Sol, info = nnls.nnlsm_blockpivot(lhs, rhs)\n",
    "        #Sol, info = NNLS(lhs, rhs)\n",
    "        H = Sol.T\n",
    "        return (W, H, H_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GR NMF Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the paper\n",
    "# https://www.hindawi.com/journals/mpe/2015/239589/\n",
    "# Deng cai graph regularized nmf.\n",
    "\n",
    "class GRNMF(object):\n",
    "    \"\"\"\n",
    "    solves min_W>=0,H>=0 ||A-WH.T||_F^2 + lambda * Tr(H.T L H) +\n",
    "                                   alpha * sum_i=1^n || h_i||_1\n",
    "    where, L = D - W. Remember, if we explicity compute L, we cannot\n",
    "    use in MU type of algorithms as the off diagonal entries of L are negative. \n",
    "\n",
    "    Equation 10 in paper https://www.hindawi.com/journals/mpe/2015/239589/\n",
    "    If lambda is zero, it is sparse NMF and alpha is 0 it is deng cai\n",
    "    graph regularized nmf\n",
    "    \"\"\"\n",
    "\n",
    "    def extract(self, A, k, max_iter=100, lambda_reg=0.1, alpha_reg=0.1):\n",
    "        \"\"\" Run a NMF algorithm\n",
    "                Parameters\n",
    "                ----------\n",
    "                A : numpy.array or scipy.sparse matrix, shape (m,n)\n",
    "                m : Number of features\n",
    "                n : Number of samples\n",
    "                k : int - target lower rank\n",
    "                lambda_reg : Regularization constant for GRNMF\n",
    "                alpha : L1 regularization constant for H matrix\n",
    "                Returns\n",
    "                -------\n",
    "                (W, H, rec)\n",
    "                W : Obtained factor matrix, shape (m,k)\n",
    "                H : Obtained coefficient matrix, shape (n,k)\n",
    "        \"\"\"\n",
    "        W = np.random.rand(A.shape[0], k)\n",
    "        H = np.random.rand(A.shape[1], k)\n",
    "        S = metrics.pairwise_kernels(A.T)\n",
    "        # normalize the distance matrix between 0 to 1\n",
    "        S = S-np.min(S)/(np.max(S)-np.min(S))\n",
    "        D = np.sum(S, axis=1)\n",
    "        norm_A = mu.norm_fro(A)\n",
    "        for i in range(1, max_iter + 1):\n",
    "            (W, H) = self.iter_solver(A, S, D, W, H, lambda_reg, alpha_reg)\n",
    "            rel_error = mu.norm_fro_err(A, W, H, norm_A) / norm_A\n",
    "        return W, H\n",
    "\n",
    "    def iter_solver(self, A, S, D, W, H, lambda_reg, alpha_reg):\n",
    "        # equation 11 of paper https://www.hindawi.com/journals/mpe/2015/239589/\n",
    "        AtW = np.matmul(A.T, W)\n",
    "        SH = np.matmul(S, H)\n",
    "        WtW = np.matmul(W.T, W)\n",
    "        HWtW = np.matmul(H, WtW)\n",
    "        DH = np.matmul(np.diagflat(D), H)\n",
    "        H_nr = 2 * (AtW + lambda_reg*SH) - alpha_reg\n",
    "        H_dr = 2 * (HWtW + lambda_reg*DH)\n",
    "        H = np.divide(H_nr, H_dr)\n",
    "        AH = np.matmul(A, H)\n",
    "        HtH = np.matmul(H.T, H)\n",
    "        WHtH = np.matmul(W, HtH)\n",
    "        W = np.divide(AH, WHtH)\n",
    "        W = W / (W.sum(axis=1)[:,np.newaxis])\n",
    "        return (W, H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Hyperspectral Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hsi_3d, _labels = read_hsi_data( os.path.join(dirname, data_filename) )\n",
    "_hsi_2d = np.reshape(_hsi_3d, (_hsi_3d.shape[0]*_hsi_3d.shape[1],_hsi_3d.shape[2]))\n",
    "\n",
    "if _labels is not None:\n",
    "    _unique_labels, _label_counts = np.unique(_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Ground Truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ground_truth_filename\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    endmembers_dict[\"GND\"], abundance_maps_dict[\"GND\"] = \\\n",
    "        read_ground_truth( os.path.join(dirname, ground_truth_filename), _hsi_3d )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _display_table(unique_labels, label_counts):\n",
    "    table = zip(unique_labels,label_counts,100.0*label_counts/sum(label_counts))\n",
    "    table_header = [\"Feature\", \"Occurrences\", \"Percent\"]\n",
    "    print tabulate(table, headers=table_header, tablefmt=\"simple\", floatfmt=(\".0f\", \".0f\", \".4f\"))\n",
    "\n",
    "def _display_labels(labels, unique_labels, label_counts):\n",
    "    fig = plt.figure(figsize=(11,4))\n",
    "    gs = mpl.gridspec.GridSpec(1, 2)\n",
    "    ax0 = fig.add_subplot(gs[0])\n",
    "    ax0.set_title(\"Labels Map\")\n",
    "    ax0.set_xticks([])\n",
    "    ax0.set_yticks([])\n",
    "    cmap = plt.get_cmap(\"jet\", np.max(labels)-np.min(labels)+1)\n",
    "    im = ax0.imshow(labels, cmap=cmap, vmin = np.min(labels)-.5, vmax = np.max(labels)+.5)\n",
    "    fig.colorbar(im, ax=ax0)\n",
    "    colors = im.cmap(im.norm(unique_labels))\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[1])\n",
    "    ax1.set_title(\"Label Distribution\")\n",
    "    ax1.bar(unique_labels, label_counts, color=colors)\n",
    "    ax1.set_ylabel(\"Count\")\n",
    "    ax1.set_xlabel(\"Label\")\n",
    "    ax1.set_xticks(unique_labels)\n",
    "\n",
    "    ax1 = ax1.twinx()\n",
    "    ax1.bar(unique_labels, label_counts/float(sum(label_counts)), color=colors)\n",
    "    ax1.set_ylabel(\"Percent\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=100)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return im\n",
    "\n",
    "def _display_regions(labels, unique_labels, im):\n",
    "    columns = 6\n",
    "    rows = int(np.ceil( len(unique_labels)/float(columns) ))\n",
    "\n",
    "    vmin, vmax = np.amin(unique_labels), np.amax(unique_labels)\n",
    "\n",
    "    fig = plt.figure(figsize=(3*columns,3*rows))\n",
    "    gs = mpl.gridspec.GridSpec(rows, columns)\n",
    "    for index,value in enumerate(unique_labels):\n",
    "        row,col = divmod(index,columns)\n",
    "\n",
    "        masked_array = np.ma.masked_not_equal(labels, value)\n",
    "\n",
    "        ax = fig.add_subplot(gs[row,col])\n",
    "        ax.set_title(\"Label {}\".format(value))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(masked_array, vmin=vmin, vmax=vmax, cmap=im.cmap)\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if _labels is not None:\n",
    "    _display_table(_unique_labels, _label_counts)\n",
    "    im = _display_labels(_labels, _unique_labels, _label_counts)\n",
    "    _display_regions(_labels, _unique_labels, im)\n",
    "else:\n",
    "    print >> sys.stderr, \"No label data to display.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cube(np.flip(_hsi_3d, 2), top_cmap=\"gist_earth\", elev=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Spectrum for a Given Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = _hsi_3d.shape[0]/2\n",
    "col = _hsi_3d.shape[1]/2\n",
    "\n",
    "spectrum = _hsi_3d[row,col,:]\n",
    "#fig = plt.figure()\n",
    "plt.plot(spectrum)\n",
    "plt.xlabel(\"Wavelength\")\n",
    "plt.ylabel(\"Brightness\")\n",
    "plt.title(\"Spectrum of Pixle {}\".format((row,col)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Several Spectral Bands for All Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bands = range(0,_hsi_3d.shape[-1],25)\n",
    "\n",
    "columns = 4\n",
    "rows = int(np.ceil( len(bands)/float(columns) ) )\n",
    "\n",
    "fig = plt.figure(figsize = (3*columns,3*rows))\n",
    "gs = mpl.gridspec.GridSpec(rows, columns)\n",
    "for index,band in enumerate(bands):\n",
    "    row,col = divmod(index, columns)\n",
    "    \n",
    "    band_image = _hsi_3d[:,:,band]\n",
    "    \n",
    "    ax = fig.add_subplot(gs[row,col])\n",
    "    ax.set_title(\"Band {}\".format(band))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(band_image, cmap=\"jet\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground Truth Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alg_name = \"GND\"\n",
    "if alg_name in endmembers_dict:\n",
    "    display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0, cmap=None)\n",
    "else:\n",
    "    print >> sys.stderr, \"No ground truth to display.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endmember Extraction Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Target Generation Process (ATGP)\n",
    "https://pysptools.sourceforge.io/eea.html#automatic-target-generation-process-atgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"ATGP\"\n",
    "if alg_name in endmember_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Iterative Pixel Purity Index (FIPPI)\n",
    "https://pysptools.sourceforge.io/eea.html#fast-iterative-pixel-purity-index-fippi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alg_name = \"FIPPI\"\n",
    "if alg_name in endmember_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-FINDR\n",
    "https://pysptools.sourceforge.io/eea.html#n-findr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alg_name = \"N-FINDR\"\n",
    "if alg_name in endmember_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Purity Index (PPI)\n",
    "https://pysptools.sourceforge.io/eea.html#pixel-purity-index-ppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"PPI\"\n",
    "if alg_name in endmember_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abundance Map Extraction Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isomap\n",
    "http://scikit-learn.org/stable/modules/manifold.html#isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alg_name = \"ISOMAP\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally Linear Embedding (LLE)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#locally-linear-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"LLE\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Locally Linear Embedding (MLLE)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#modified-locally-linear-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"MLLE\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian-Based Locally Linear Embedding (HLLE)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#hessian-eigenmapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"HLLE\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Embedding (SE)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#spectral-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"SE\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Tangent Space Alignment (LTSA)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#local-tangent-space-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"LTSA\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Multi-Dimensional Scaling (MMDS)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#metric-mds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"MMDS\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonmetric Multi-Dimensional Scaling (NMDS)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#nonmetric-mdseigenmapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"NMDS\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-distributed Stochastic Neighbor Embedding (TSNE)\n",
    "http://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"TSNE\"\n",
    "if alg_name in abundance_maps_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Unmixing Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis (PCA)\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alg_name = \"PCA\"\n",
    "if alg_name in joint_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonnegative Matrix Factorization (NMF)\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"NMF\"\n",
    "if alg_name in joint_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint Nonnegative Matrix Factorization (Joint-NMF)\n",
    "https://www.hindawi.com/journals/mpe/2015/239589/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_name = \"Joint-NMF\"\n",
    "if alg_name in joint_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Regularized Nonnegative Matrix Factorization (GR-NMF)\n",
    "https://www.hindawi.com/journals/mpe/2015/239589/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alg_name = \"GR-NMF\"\n",
    "if alg_name in joint_algorithms:\n",
    "    try:\n",
    "        endmembers_dict[alg_name], abundance_maps_dict[alg_name] = \\\n",
    "            run_algorithm(alg_name, dirname, n_endmembers, n_neighbors, _hsi_3d, compute=compute, save_results=save_results)\n",
    "        display_components(endmembers_dict[alg_name], abundance_maps_dict[alg_name], alg_name, vmin=0.0)\n",
    "    except Exception as ex:\n",
    "        if compute == \"cache_only\":\n",
    "            print >> sys.stderr, ex\n",
    "            print >> sys.stderr, \"cache results not avaliable, skipping\", alg_name\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print >> sys.stderr, \"Skipping\", alg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endmember_results = list(set(endmember_algorithms) & set(endmembers_dict.keys()))\n",
    "abundance_maps_results = list(set(abundance_maps_algorithms) & set(endmembers_dict.keys()))\n",
    "joint_results = list(set(joint_algorithms) & set(endmembers_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endmember Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth Endmember Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Endmember vs. Endmember Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"GND\" in endmembers_dict:\n",
    "    alg2 = \"GND\"\n",
    "    for alg1 in endmember_results:\n",
    "        compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)\n",
    "else:\n",
    "    print >> sys.stderr, \"No ground truth to compare against.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Endmember vs. Abundance Maps Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"GND\" in endmembers_dict:\n",
    "    alg2 = \"GND\"\n",
    "    for alg1 in abundance_maps_results:\n",
    "        compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)\n",
    "else:\n",
    "    print >> sys.stderr, \"No ground truth to compare against.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Endmember vs. Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"GND\" in endmembers_dict:\n",
    "    alg2 = \"GND\"\n",
    "    for alg1 in joint_results:\n",
    "        compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)\n",
    "else:\n",
    "    print >> sys.stderr, \"No ground truth to compare against.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Algorithm Endmember Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endmember Comparison for Endmember Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.combinations(endmember_results, 2):\n",
    "    compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endmember Comparison for Abundance Maps Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.combinations(abundance_maps_results, 2):\n",
    "    compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endmember Comparison for Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.combinations(joint_results, 2):\n",
    "    compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Algorithm Endmember Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endmember Comparison for Endmember Algorithms vs. Abundance Maps Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.product(endmember_results, abundance_maps_results):\n",
    "    compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endmember Comparison for Endmember Algorithms vs. Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.product(endmember_results, joint_results):\n",
    "    compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endmember Comparison for Abundance Maps Algorithms vs. Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.product(abundance_maps_results, joint_results):\n",
    "    compare_endmembers(endmembers_dict[alg1], endmembers_dict[alg2], alg1, alg2, metric=endmember_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abundance Maps Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth Abundance Maps Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Abundance Maps vs. Endmember Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"GND\" in abundance_maps_dict:\n",
    "    alg2 = \"GND\"\n",
    "    for alg1 in endmember_results:\n",
    "        break\n",
    "        compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)\n",
    "else:\n",
    "    print >> sys.stderr, \"No ground truth to compare against.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Abundance Maps vs. Abundance Maps Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"GND\" in abundance_maps_dict:\n",
    "    alg2 = \"GND\"\n",
    "    for alg1 in abundance_maps_results:\n",
    "        compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)\n",
    "else:\n",
    "    print >> sys.stderr, \"No ground truth to compare against.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Abundance Maps vs. Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"GND\" in abundance_maps_dict:\n",
    "    alg2 = \"GND\"\n",
    "    for alg1 in joint_results:\n",
    "        compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)\n",
    "else:\n",
    "    print >> sys.stderr, \"No ground truth to compare against.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Algorithm Abundance Maps Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abundance Maps Comparison for Endmember Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.combinations(endmember_results, 2):\n",
    "    compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abundance Maps Comparison for Abundance Maps Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.combinations(abundance_maps_results, 2):\n",
    "    compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abundance Maps Comparison for Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.combinations(joint_results, 2):\n",
    "    compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Algorithm Abundance Maps Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abundance Maps Comparison for Endmember Algorithms vs. Abundance Maps Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.product(endmember_results, abundance_maps_results):\n",
    "    compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abundance Maps Comparison for Endmember Algorithms vs. Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.product(endmember_results, joint_results):\n",
    "    compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abundance Maps Comparison for Abundance Maps Algorithms vs. Joint Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg1, alg2 in itertools.product(abundance_maps_results, joint_results):\n",
    "    compare_abundance_maps(abundance_maps_dict[alg1], abundance_maps_dict[alg2], alg1, alg2, metric=abundance_maps_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-of-Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
